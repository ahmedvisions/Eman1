import os
import shutil
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.5'
os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'

tf.keras.backend.clear_session()

train_dir = 'data/train'
validation_dir = 'data/validation'

def convert_images_to_rgba(directory):
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.png') or file.endswith('.jpeg') or file.endswith('.jpg'):
                img_path = os.path.join(root, file)
                img = Image.open(img_path)
                if img.mode == 'P' or img.mode == 'L':
                    img = img.convert('RGBA')
                    img.save(img_path)

input_path = '/kaggle/input/car-and-bike-1/Car-Bike-Dataset'

os.makedirs('data/train/cars', exist_ok=True)
os.makedirs('data/train/bikes', exist_ok=True)
os.makedirs('data/validation/cars', exist_ok=True)
os.makedirs('data/validation/bikes', exist_ok=True)

car_images = os.listdir(os.path.join(input_path, 'Car'))
bike_images = os.listdir(os.path.join(input_path, 'Bike'))

for i, img in enumerate(car_images):
    if i < int(0.8 * len(car_images)):
        shutil.copy(os.path.join(input_path, 'Car', img), 'data/train/cars')
    else:
        shutil.copy(os.path.join(input_path, 'Car', img), 'data/validation/cars')

for i, img in enumerate(bike_images):
    if i < int(0.8 * len(bike_images)):
        shutil.copy(os.path.join(input_path, 'Bike', img), 'data/train/bikes')
    else:
        shutil.copy(os.path.join(input_path, 'Bike', img), 'data/validation/bikes')

convert_images_to_rgba(train_dir)
convert_images_to_rgba(validation_dir)

train_datagen = ImageDataGenerator(rescale=1./255)
validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary'
)

print(f"Steps per epoch (train): {len(train_generator)}")
print(f"Validation steps: {len(validation_generator)}")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

steps_per_epoch = len(train_generator)
validation_steps = len(validation_generator)

history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=15,
    validation_data=validation_generator,
    validation_steps=validation_steps
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

plt.show()

loss, accuracy = model.evaluate(validation_generator)
print(f'Validation Accuracy: {accuracy * 100:.2f}%')
print(f'Validation Loss:Â {loss:.4f}')
